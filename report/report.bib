@inproceedings{Luersen2004,
author="Luersen , M.A.
and Le Riche , R.
and Guyon , F.",
title={{A constrained, globalized, and bounded Nelder--Mead method for engineering optimization}},
journal="Structural and Multidisciplinary Optimization",
year="2004",
day="01",
volume="27",
number="1",
pages="43--54",
abstract="One of the fundamental difficulties in engineering design is the multiplicity of local solutions. This has triggered much effort in the development of global search algorithms. Globality, however, often has a prohibitively high numerical cost for real problems. A fixed cost local search, which sequentially becomes global, is developed in this work. Globalization is achieved by probabilistic restarts. A spacial probability of starting a local search is built based on past searches. An improved Nelder--Mead algorithm is the local optimizer. It accounts for variable bounds and nonlinear inequality constraints. It is additionally made more robust by reinitializing degenerated simplexes. The resulting method, called the Globalized Bounded Nelder--Mead (GBNM) algorithm, is particularly adapted to tackling multimodal, discontinuous, constrained optimization problems, for which it is uncertain that a global optimization can be afforded. Numerical experiments are given on two analytical test functions and two composite laminate design problems. The GBNM method compares favorably with an evolutionary algorithm, both in terms of numerical cost and accuracy. ",
issn="1615-1488",
doi="10.1007/s00158-003-0320-9",
url="https://doi.org/10.1007/s00158-003-0320-9"
}

@inproceedings{Kurek2016,
author = {Kurek, M and Deisenroth, MP and Luk, W and Todman, T},
doi = {10.1109/FCCM.2016.29},
pages = {84--87},
publisher = {IEEE},
title = {{Knowledge Transfer in Automatic Optimisation of Reconfigurable Designs}},
url = {http://dx.doi.org/10.1109/FCCM.2016.29},
year = {2016}
}

@inproceedings{Xi2004,
author = {Xi, Bowei and Liu, Zhen and Raghavachari, Mukund and Xia, Cathy H. and Zhang, Li},
title = {{A Smart Hill-climbing Algorithm for Application Server Configuration}},
booktitle = {Proceedings of the 13th International Conference on World Wide Web},
series = {WWW '04},
year = {2004},
isbn = {1-58113-844-X},
location = {New York, NY, USA},
pages = {287--296},
numpages = {10},
url = {http://doi.acm.org/10.1145/988672.988711},
doi = {10.1145/988672.988711},
acmid = {988711},
publisher = {ACM},
address = {New York, NY, USA},
keywords = {automatic tuning, gradient method, importance sampling, simulated annealing, system configuration}
} 
               
               
@inproceedings{Nicholson2015,
author = {Nicholson, W},
title = {{Accelerating Efficient Global Optimisation for Reconfigurable Computing}},
institution = {Imperial College London},
year = {2015}
}

@Article{Jones1998,
author="Jones, Donald R.
and Schonlau, Matthias
and Welch, William J.",
title={{Efficient Global Optimization of Expensive Black-Box Functions}},
journal="Journal of Global Optimization",
year="1998",
day="01",
volume="13",
number="4",
pages="455--492",
abstract="In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome.",
issn="1573-2916",
doi="10.1023/A:1008306431147",
url="https://doi.org/10.1023/A:1008306431147"
}

@Article{Arram2017,
author="Arram. J",
title={{FPGA Acceleration of DNA Sequencing Analysis and Storage}},
year="2017",
}

@Inbook{Tse2012,
author="Tse, Anson H. T.
and Chow, Gary C. T.
and Jin, Qiwei
and Thomas, David B.
and Luk, Wayne",
editor="Choy, Oliver C. S.
and Cheung, Ray C. C.
and Athanas, Peter
and Sano, Kentaro",
title={{Optimising Performance of Quadrature Methods with Reduced Precision}},
bookTitle="Reconfigurable Computing: Architectures, Tools and Applications: 8th International Symposium, ARC 2012, Hong Kong, China, March 19-23, 2012. Proceedings",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="251--263",
abstract="This paper presents a generic precision optimisation methodology for quadrature computation targeting reconfigurable hardware to maximise performance at a given error tolerance level. The proposed methodology optimises performance by considering integration grid density versus mantissa size of floating-point operators. The optimisation provides the number of integration points and mantissa size with maximised throughput while meeting given error tolerance requirement. Three case studies show that the proposed reduced precision designs on a Virtex-6 SX475T FPGA are up to 6 times faster than comparable FPGA designs with double precision arithmetic. They are up to 15.1 times faster and 234.9 times more energy efficient than an i7-870 quad-core CPU, and are 1.2 times faster and 42.2 times more energy efficient than a Tesla C2070 GPU.",
isbn="978-3-642-28365-9",
doi="10.1007/978-3-642-28365-9_21",
url="https://doi.org/10.1007/978-3-642-28365-9_21"
}
